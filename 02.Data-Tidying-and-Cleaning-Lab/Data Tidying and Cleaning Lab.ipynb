{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "078d90d4-aec6-40fe-997f-ce63c962d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your imports here\n",
    "import pandas as pd\n",
    "import itertools as iter\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa71be-5d01-4efc-85fa-a019fe92a39a",
   "metadata": {},
   "source": [
    "# Data Tidying and Cleaning Lab\n",
    "## Reading, tidying and cleaning data. Preparing data for exploration, mining, analysis and learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259927d3-4ad5-471e-b34b-114f07127a39",
   "metadata": {},
   "source": [
    "In this lab, you'll be working with the Coffee Quality Index dataset, located [here](https://www.kaggle.com/datasets/volpatto/coffee-quality-database-from-cqi). For convenience (and to save trouble in case you can't download files, or someone uploads a newer version), I've provided the dataset in the `data/` folder. The metadata (description) is at the Kaggle link. For this lab, you'll only need `merged_data_cleaned.csv`, as it is the concatenation of the other two datasets.\n",
    "\n",
    "In this (and the following labs), you'll get several questions and problems. Do your analysis, describe it, use any tools and plots you wish, and answer. You can create any amount of cells you'd like.\n",
    "\n",
    "Sometimes, the answers will not be unique, and they will depend on how you decide to approach and solve the problem. This is usual - we're doing science after all!\n",
    "\n",
    "It's a good idea to save your clean dataset after all the work you've done to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450ac8e-523c-46f8-a410-9ad5af4cfc14",
   "metadata": {},
   "source": [
    "### Problem 1. Read the dataset (1 point)\n",
    "This should be self-explanatory. The first column is the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df50bd71-ea2a-4db9-814d-c49f782ca101",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_initial = pd.read_csv(\"data/merged_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278e2a8-56b4-4b1a-ad71-e7b920321e37",
   "metadata": {},
   "source": [
    "### Problem 2. Observations and features (1 point)\n",
    "How many observations are there? How many features? Which features are numerical, and which are categorical?\n",
    "\n",
    "**Note:** Think about the _meaning_, not the data types. The dataset hasn't been thoroughly cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bb9dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_all(func, test_cases: list[tuple[any, any, str]]):\n",
    "  for (input, expected, message) in test_cases:\n",
    "    actual = func(input)\n",
    "    assert actual == expected,  f'{message}. Input: \"{input}\", epxected: \"{expected}\", actual: \"{actual}\"'\n",
    "\n",
    "test_cases_attribute = \"test_cases\"\n",
    "\n",
    "def define_test_cases(func, test_cases: list[tuple[any, any, str]]):\n",
    "  func.__setattr__(test_cases_attribute, test_cases)\n",
    "\n",
    "def assert_function_works(func):\n",
    "  def try_get_name(func): \n",
    "    return func.__name__ if callable(func) else func\n",
    "  assert hasattr(func,test_cases_attribute), f'the provided function \"{try_get_name}\" has no property {test_cases_attribute}. Consider calling {define_test_cases.__name__} to set them'\n",
    "  assert_all(func, getattr(func, test_cases_attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7d17c46-5475-4c33-9c35-b7cf56ac41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations: 1339\n",
      "features: 44\n",
      "categorical: 24\n",
      "['Species(object)', 'Owner(object)', 'Country.of.Origin(object)', 'Farm.Name(object)', 'Lot.Number(object)', 'Mill(object)', 'ICO.Number(object)', 'Company(object)', 'Altitude(object)', 'Region(object)', 'Producer(object)', 'Bag.Weight(object)', 'In.Country.Partner(object)', 'Harvest.Year(object)', 'Grading.Date(object)', 'Owner.1(object)', 'Variety(object)', 'Processing.Method(object)', 'Color(object)', 'Expiration(object)', 'Certification.Body(object)', 'Certification.Address(object)', 'Certification.Contact(object)', 'unit_of_measurement(object)']\n",
      "numerical: 20\n",
      "['Unnamed: 0(int64)', 'Number.of.Bags(int64)', 'Aroma(float64)', 'Flavor(float64)', 'Aftertaste(float64)', 'Acidity(float64)', 'Body(float64)', 'Balance(float64)', 'Uniformity(float64)', 'Clean.Cup(float64)', 'Sweetness(float64)', 'Cupper.Points(float64)', 'Total.Cup.Points(float64)', 'Moisture(float64)', 'Category.One.Defects(int64)', 'Quakers(float64)', 'Category.Two.Defects(int64)', 'altitude_low_meters(float64)', 'altitude_high_meters(float64)', 'altitude_mean_meters(float64)']\n"
     ]
    }
   ],
   "source": [
    "(rows_count, columns_count) = coffee_initial.shape\n",
    "\n",
    "categorical = \"categorical\"\n",
    "numerical = \"numerical\"\n",
    "other = \"other\"\n",
    "numerical_types = [float, int, complex, np.int8, np.int16, np.int32, np.int64 ]\n",
    "\n",
    "def get_series_type(s: pd.Series):\n",
    "  categorical_types = [str]\n",
    "  if (s.dtype in numerical_types):\n",
    "    return numerical\n",
    "  if(s.dtype in categorical_types):\n",
    "    return categorical\n",
    "  # another try whether all except NaN are strings\n",
    "  if (all( type(item) == str for item in s.dropna() )):\n",
    "    return categorical\n",
    "  return other\n",
    "  \n",
    "\n",
    "def get_proposed_features(df: pd.DataFrame):\n",
    "  return [ (colName, get_series_type(series), series.dtype ) for (colName, series) in [(colName, df[colName]) for colName in df]]\n",
    "  \n",
    "def print_proposed_features(df: pd.DataFrame):\n",
    "  proposed_features = get_proposed_features(df)\n",
    "  keyfunc =  lambda x: x[1]\n",
    "  \n",
    "  for key, group in iter.groupby(sorted(proposed_features, key=keyfunc ), keyfunc ):\n",
    "    group_as_list = list(group)\n",
    "    print(f'{key}: {len(group_as_list)}')\n",
    "    print([ f'{colName}({dtype})' for colName, series_type, dtype in group_as_list])\n",
    "\n",
    "print(f'observations: {rows_count}')\n",
    "print(f'features: {columns_count}')\n",
    "print_proposed_features(coffee_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a135a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = \"numerical\"\n",
    "other = \"other\"\n",
    "\n",
    "def get_series_type(s: pd.Series):\n",
    "  numerical_types = [float, int, complex, np.int8, np.int16, np.int32, np.int64 ]\n",
    "  categorical_types = [str]\n",
    "  if (s.dtype in numerical_types):\n",
    "    return numerical\n",
    "  if(s.dtype in categorical_types):\n",
    "    return categorical\n",
    "  # another try whether all except NaN are strings\n",
    "  if (all( type(item) == str for item in s.dropna() )):\n",
    "    return categorical\n",
    "  return other\n",
    "  \n",
    "\n",
    "def get_proposed_features(df: pd.DataFrame):\n",
    "  return [ (colName, get_series_type(series), series.dtype ) for (colName, series) in [(colName, df[colName]) for colName in df]]\n",
    "  \n",
    "def print_proposed_features(df: pd.DataFrame):\n",
    "  proposed_features = get_proposed_features(df)\n",
    "  keyfunc =  lambda x: x[1]\n",
    "  \n",
    "  for key, group in iter.groupby(sorted(proposed_features, key=keyfunc ), keyfunc ):\n",
    "    group_as_list = list(group)\n",
    "    print(f'{key}: {len(group_as_list)}')\n",
    "    print([ f'{colName}({dtype})' for colName, series_type, dtype in group_as_list])\n",
    "\n",
    "print(f'observations: {rows_count}')\n",
    "print(f'features: {columns_count}')\n",
    "print_proposed_features(coffee_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b745e68-35eb-4acb-b39f-513137f0ee4b",
   "metadata": {},
   "source": [
    "### Problem 3. Column manipulation (1 point)\n",
    "Make the column names more Pythonic (which helps with the quality and... aesthetics). Convert column names to `snake_case`, i.e. `species`, `country_of_origin`, `ico_number`, etc. Try to not do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "301e9f3f-afd6-4a91-a32f-1974584694ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unnamed: 0', 'species', 'owner', 'country_of_origin', 'farm_name',\n",
       "       'lot_number', 'mill', 'ico_number', 'company', 'altitude', 'region',\n",
       "       'producer', 'number_of_bags', 'bag_weight', 'in_country_partner',\n",
       "       'harvest_year', 'grading_date', 'owner_1', 'variety',\n",
       "       'processing_method', 'aroma', 'flavor', 'aftertaste', 'acidity', 'body',\n",
       "       'balance', 'uniformity', 'clean_cup', 'sweetness', 'cupper_points',\n",
       "       'total_cup_points', 'moisture', 'category_one_defects', 'quakers',\n",
       "       'color', 'category_two_defects', 'expiration', 'certification_body',\n",
       "       'certification_address', 'certification_contact', 'unit_of_measurement',\n",
       "       'altitude_low_meters', 'altitude_high_meters', 'altitude_mean_meters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_snake_case(input: str, separator = '.'):\n",
    "  if(type(input) != str):\n",
    "    return input\n",
    "  stripped_input = input.strip()\n",
    "  split_values = [ val.strip().lower() for val in stripped_input.split(separator) if len(val.strip()) > 0]\n",
    "  if (len(split_values) == 1):\n",
    "    return split_values[0]\n",
    "  return '_'.join(split_values)\n",
    "\n",
    "define_test_cases(to_snake_case, [\n",
    "  (5, 5, 'If nto a string - should not modify the input'),\n",
    "  ('Petar', 'petar', 'Should lowercase the input'),\n",
    "  ('Price. noVAT', 'price_novat', 'should sanitize the split parts'),\n",
    "  ('sales_count','sales_count', 'Should not modify the input'),\n",
    "  ('  sales_count ','sales_count', 'Should trim leading and trailing spaces'),\n",
    "])\n",
    "\n",
    "assert_function_works(to_snake_case)\n",
    " \n",
    "coffee_initial_renames = coffee_initial.rename(to_snake_case, axis='columns')\n",
    "coffee_initial_renames.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53c4c6-6eb9-4c92-bd39-89286fe4c86e",
   "metadata": {},
   "source": [
    "### Problem 4. Bag weight (1 point)\n",
    "What's up with the bag weights? Make all necessary changes to the column values. Don't forget to document your methods and assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e97f3d0-1223-49a7-99a9-51a65e4ff4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All units\n",
      "[('kg', 1196), ('kg,lbs', 2), ('lbs', 114), ('no_measure', 27)]\n"
     ]
    }
   ],
   "source": [
    "no_measure = 'no_measure'\n",
    "no_value = 'no_value'\n",
    "\n",
    "def extract_value_components(input: str) -> tuple[float | None, str]:\n",
    "  if (type(input) != str):\n",
    "    return no_measure  \n",
    "  stripped_input = input.strip()\n",
    "  split_values = [ val.strip().lower() for val in stripped_input.split(' ') if len(val.strip()) > 0]\n",
    "  if (len(split_values) == 0):\n",
    "    return (None, no_value)\n",
    "  if (len(split_values) == 1):\n",
    "    return (None, no_measure)\n",
    "  value = None\n",
    "  try:\n",
    "    value = float(split_values[0])\n",
    "  except ValueError:\n",
    "    print(f'Provided value {split_values[0]} is nto a float')\n",
    "  return (value, ' '.join(split_values[1:]))\n",
    "\n",
    "def extract_measrure(input: str):\n",
    "  (_, unit) = extract_value_components(input)\n",
    "  return unit\n",
    "\n",
    "def extract_value_as_float(input: str):\n",
    "  (value, _) = extract_value_components(input)\n",
    "  return value\n",
    "  \n",
    "\n",
    "def get_all_measures(series: pd.Series) -> list[tuple[str, int]] :\n",
    "  series_no_na = series.dropna()\n",
    "  return [\n",
    "    (key, len(list(group))) for\n",
    "    key, group in\n",
    "    iter.groupby(sorted(series_no_na, key=extract_measrure), extract_measrure)]\n",
    "\n",
    "bag_weight_all_measures = get_all_measures(coffee_initial_renames.bag_weight)\n",
    "\n",
    "print('All units')\n",
    "print(bag_weight_all_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4b9cb",
   "metadata": {},
   "source": [
    "The **bag_weight** series should be weight. We see mixed value with or withut measures. Some are in kg, others are in lbs.\n",
    "We have values in `kg`, values in `lbs` and values without `unit`.\n",
    "Our approach would be to convert the data as follows:\n",
    "1. If unit is `lbs` -> we will convert it using $ f(x)_{x \\text{ in lbs}} = 0.45359237*x \\text{ kg} $\n",
    "2. For unit `kg,lbs` or those without `unit` - we will assign NA value to them.\n",
    "\n",
    "In the end we will remove the unit and cast the column as float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5e84366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1310.000000\n",
       "mean       182.608718\n",
       "std       1540.260390\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%         50.000000\n",
       "75%         69.000000\n",
       "max      19200.000000\n",
       "Name: bag_weight, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wight_as_float(input: str | None, none_values = ['kg,lbs']) -> float:\n",
    "  if (input is None):\n",
    "    return input\n",
    "  assert type(input) is str, f'Incorrect input param. String or None is required. Provided: ${type(input)}'\n",
    "  (value, unit) = extract_value_components(input)\n",
    "  if ([no_measure, no_value].count(unit)):\n",
    "    return None\n",
    "  if(none_values.count(unit)):\n",
    "    return None\n",
    "  if (unit == 'lbs'):\n",
    "    return value*0.45359237\n",
    "  return value\n",
    "\n",
    "define_test_cases(get_wight_as_float, [\n",
    "  (None, None, 'Should return None if none i provided'),\n",
    "  ('', None, 'No value should return None'),\n",
    "  ('5 ', None, 'No measure should return None'),\n",
    "  ('15  kg,lbs', None, 'Both units should return None'),\n",
    "  ('1 lbs', 0.45359237, 'Should convert lbs to kg'),\n",
    "  ('15.6 kg', 15.6, 'Should just extract the value if unit is kg')\n",
    "])\n",
    "\n",
    "assert_function_works(get_wight_as_float)\n",
    "\n",
    "coffee_initial_renames.bag_weight = coffee_initial_renames.bag_weight.apply(get_wight_as_float)\n",
    "coffee_initial_renames.bag_weight.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28938dda",
   "metadata": {},
   "source": [
    "### Problem 5. Dates (1 point)\n",
    "This should remind you of problem 4 but it's slightly nastier. Fix the harvest years, document the process.\n",
    "\n",
    "While you're here, fix the expiration dates, and grading dates. Unlike the other column, these should be dates (`pd.to_datetime()` is your friend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92f6b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harvest_year(input: str | None, min = 2000, max = 2050) -> int | None:\n",
    "  def to_int_year(input: any) -> int | None:\n",
    "    int_val = int(input)\n",
    "    return int_val if min <= int_val and int_val <= max else None\n",
    "\n",
    "  if (input is None):\n",
    "    return input\n",
    "  if(numerical_types.count(type(input)) > 0):\n",
    "    return None if np.isnan(input) else to_int_year(input)\n",
    "  all_matches = re.findall('\\d\\d\\d\\d', input)\n",
    "  if (len(all_matches) == 0):\n",
    "    return None\n",
    "  return to_int_year(all_matches[0])\n",
    "\n",
    "  \n",
    "  \n",
    "assert_all(get_harvest_year,[\n",
    "  (None, None, 'If none provided, should return None'),\n",
    "  ('Test', None, 'If no year can be found, return None'),\n",
    "  ('Martch 2008', 2008, 'If no year can be found, return None'),\n",
    "  ('Sept 2009 - April 2010', 2009, 'Should return the first met year'),\n",
    "  ('2012', 2012, 'Should jsut parse the date'),\n",
    "  ('1567', None, 'Should return None if year is less tahn min'),\n",
    "  ('3569', None, 'Should return None if year is more than max value'),\n",
    "  (2012.0, 2012, 'Should convert float to int'),\n",
    "  (np.NaN, None, 'Should return none if valeu is float Nan')\n",
    "])\n",
    "\n",
    "coffee_initial_renames.harvest_year = coffee_initial_renames.harvest_year.apply(get_harvest_year)\n",
    "coffee_initial_renames.harvest_year.describe()\n",
    "\n",
    "coffee_initial_renames.expiration = pd.to_datetime(coffee_initial_renames.expiration, format='mixed')\n",
    "coffee_initial_renames.grading_date = pd.to_datetime(coffee_initial_renames.grading_date, format='mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d2a12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dff33b4-c94d-43b3-bab3-97eabb862a37",
   "metadata": {},
   "source": [
    "### Problem 6. Countries (1 point)\n",
    "How many coffees are there with unknown countries of origin? What can you do about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851c1a8-0420-4dba-ac27-487bae4318be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0aa6f30-4b93-4f23-95e0-2cafb7152c6c",
   "metadata": {},
   "source": [
    "### Problem 7. Owners (1 point)\n",
    "There are two suspicious columns, named `Owner`, and `Owner.1` (they're likely called something different after you solved problem 3). Do something about them. Is there any link to `Producer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc1689-33f6-4446-bfc3-c4b4e69eccf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c53923-1b72-4500-af0a-47fdca9f57e9",
   "metadata": {},
   "source": [
    "### Problem 8. Coffee color by country and continent (1 point)\n",
    "Create a table which shows how many coffees of each color are there in every country. Leave the missing values as they are.\n",
    "\n",
    "**Note:** If you ask me, countries should be in rows, I prefer long tables much better than wide ones.\n",
    "\n",
    "Now do the same for continents. You know what continent each country is located in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbe6a9-ca71-4826-806d-562bc30b40d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27095ced-7179-4ee4-94d3-7d94450b4120",
   "metadata": {},
   "source": [
    "### Problem 9. Ratings (1 point)\n",
    "The columns `Aroma`, `Flavor`, etc., up to `Moisture` represent subjective ratings. Explore them. Show the means and range; draw histograms and / or boxplots as needed. You can even try correlations if you want. What's up with all those ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ee355-dcbb-4657-a814-cdcfbd455c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92054218-978d-48c6-b7aa-36226837354c",
   "metadata": {},
   "source": [
    "### Problem 10. High-level errors (1 point)\n",
    "Check the countries against region names, altitudes, and companies. Are there any discrepancies (e.g. human errors, like a region not matching the country)? Take a look at the (cleaned) altitudes; there has been a lot of preprocessing done to them. Was it done correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971e5dd-4bb1-4ad6-bcbc-3cceab758f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c3b5118-9f8e-45c2-a200-1be89fa4b3bf",
   "metadata": {},
   "source": [
    "### * Problem 11. Clean and explore at will\n",
    "The dataset claimed to be clean, but we were able to discover a lot of things to fix and do better.\n",
    "\n",
    "Play around with the data as much as you wish, and if you find variables to tidy up and clean - by all means, do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928732cf-7ef4-471a-9818-139dd519eb45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
